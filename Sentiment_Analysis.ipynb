{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset loaded successfully.\n"
                    ]
                }
            ],
            "source": [
                "# Import Libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                "from scipy.special import softmax\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "import torch\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Load Dataset\n",
                "try:\n",
                "    df = pd.read_csv('data /smart_watch_review.csv')\n",
                "    print(\"Dataset loaded successfully.\")\n",
                "except FileNotFoundError:\n",
                "    print(\"Error: File not found.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Labels generated.\n"
                    ]
                }
            ],
            "source": [
                "# Generate Ground Truth Labels\n",
                "rating_col = None\n",
                "for col in df.columns:\n",
                "    if 'rating' in col.lower() or 'star' in col.lower():\n",
                "        rating_col = col\n",
                "        break\n",
                "\n",
                "if rating_col:\n",
                "    def extract_rating(val):\n",
                "        try:\n",
                "            return float(str(val).split()[0])\n",
                "        except:\n",
                "            return 3.0\n",
                "    df['numeric_rating'] = df[rating_col].apply(extract_rating)\n",
                "    \n",
                "    def get_label(rating):\n",
                "        if rating > 3: return 'Positive'\n",
                "        elif rating < 3: return 'Negative'\n",
                "        else: return 'Neutral'\n",
                "    \n",
                "    df['Sentiment'] = df['numeric_rating'].apply(get_label)\n",
                "    print(\"Labels generated.\")\n",
                "else:\n",
                "    print(\"Warning: No rating column found.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "BERT Model Loaded.\n"
                    ]
                }
            ],
            "source": [
                "# Load Pre-trained Model (Product Reviews 1-5 stars)\n",
                "MODEL = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
                "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
                "print(\"BERT Model Loaded.\")\n",
                "\n",
                "# Prediction Function\n",
                "def predict_sentiment(text):\n",
                "    try:\n",
                "        encoded_text = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
                "        output = model(**encoded_text)\n",
                "        scores = output.logits[0].detach().numpy()\n",
                "        scores = softmax(scores)\n",
                "        \n",
                "        # Labels: 0->1 star, 1->2 stars, 2->3 stars, 3->4 stars, 4->5 stars\n",
                "        star_rating = np.argmax(scores) + 1\n",
                "        \n",
                "        if star_rating <= 2:\n",
                "            return 'Negative'\n",
                "        elif star_rating == 3:\n",
                "            return 'Neutral'\n",
                "        else:\n",
                "            return 'Positive'\n",
                "    except:\n",
                "        return \"Neutral\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Unique numeric ratings: [3. 2. 5. 1. 4.]\n",
                        "Unique sentiments: ['Neutral' 'Negative' 'Positive']\n",
                        "Running predictions on first 500 rows for verification...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 500/500 [00:14<00:00, 34.05it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Accuracy on Sample: 29.00%\n",
                        "\n",
                        "Classification Report:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "    Negative       0.00      0.00      0.00       197\n",
                        "     Neutral       0.18      0.36      0.24       109\n",
                        "    Positive       0.37      0.55      0.44       194\n",
                        "\n",
                        "    accuracy                           0.29       500\n",
                        "   macro avg       0.18      0.30      0.23       500\n",
                        "weighted avg       0.18      0.29      0.22       500\n",
                        "\n",
                        "\n",
                        "Misclassified Examples:\n",
                        "Text: Amazing smartwatch with excellent performance. The heart rate tracking is very accurate, and step co...\n",
                        "True: Neutral (Rating: 3.0) | Pred: Positive\n",
                        "--------------------------------------------------\n",
                        "Text: Product quality is good but the strap material could have been better. Features work fine and notifi...\n",
                        "True: Negative (Rating: 2.0) | Pred: Neutral\n",
                        "--------------------------------------------------\n",
                        "Text: The watch works fine but sometimes hangs while switching between apps. Battery performance varies a ...\n",
                        "True: Negative (Rating: 2.0) | Pred: Neutral\n",
                        "--------------------------------------------------\n",
                        "Text: Superb experience! The watch exceeded expectations in terms of design and performance. Fitness featu...\n",
                        "True: Neutral (Rating: 3.0) | Pred: Positive\n",
                        "--------------------------------------------------\n",
                        "Text: The watch works fine but sometimes hangs while switching between apps. Battery performance varies a ...\n",
                        "True: Negative (Rating: 2.0) | Pred: Neutral\n",
                        "--------------------------------------------------\n",
                        "Text: Amazing smartwatch with excellent performance. The heart rate tracking is very accurate, and step co...\n",
                        "True: Neutral (Rating: 3.0) | Pred: Positive\n",
                        "--------------------------------------------------\n",
                        "Text: Overall a very good purchase. Build quality is solid and the watch feels comfortable to wear through...\n",
                        "True: Negative (Rating: 2.0) | Pred: Positive\n",
                        "--------------------------------------------------\n",
                        "Text: The watch performs really well for day-to-day usage. Battery backup lasts more than expected, and th...\n",
                        "True: Negative (Rating: 1.0) | Pred: Positive\n",
                        "--------------------------------------------------\n",
                        "Text: Product quality is good but the strap material could have been better. Features work fine and notifi...\n",
                        "True: Positive (Rating: 4.0) | Pred: Neutral\n",
                        "--------------------------------------------------\n",
                        "Text: The watch works fine but sometimes hangs while switching between apps. Battery performance varies a ...\n",
                        "True: Positive (Rating: 4.0) | Pred: Neutral\n",
                        "--------------------------------------------------\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
                        "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
                        "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
                    ]
                }
            ],
            "source": [
                "# Debug Data Extraction\n",
                "print(\"Unique numeric ratings:\", df['numeric_rating'].unique())\n",
                "print(\"Unique sentiments:\", df['Sentiment'].unique())\n",
                "\n",
                "# Run Predictions (on a sample to save time, or full dataset)\n",
                "print(\"Running predictions on first 500 rows for verification...\")\n",
                "sample_df = df.head(500).copy()\n",
                "tqdm.pandas()\n",
                "sample_df['Predicted'] = sample_df['review'].progress_apply(predict_sentiment)\n",
                "\n",
                "# Evaluate\n",
                "acc = accuracy_score(sample_df['Sentiment'], sample_df['Predicted'])\n",
                "print(f\"\\nAccuracy on Sample: {acc*100:.2f}%\")\n",
                "print(\"\\nClassification Report:\\n\", classification_report(sample_df['Sentiment'], sample_df['Predicted']))\n",
                "\n",
                "# Show Misclassified Examples\n",
                "print(\"\\nMisclassified Examples:\")\n",
                "errors = sample_df[sample_df['Sentiment'] != sample_df['Predicted']].head(10)\n",
                "for idx, row in errors.iterrows():\n",
                "    print(f\"Text: {row['review'][:100]}...\")\n",
                "    print(f\"True: {row['Sentiment']} (Rating: {row['numeric_rating']}) | Pred: {row['Predicted']}\")\n",
                "    print(\"-\" * 50)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
